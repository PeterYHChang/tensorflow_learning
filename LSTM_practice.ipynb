{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2300cbd0-fdca-4fd3-aaf0-3d416823a382",
   "metadata": {},
   "source": [
    "# 下載路透社資料，已有資料為多則新聞文本，並且已將文字 embedding，同時對應到 46種主題中其中一種。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86464ab-cb79-4167-999c-4317af1d3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ee9858-f507-4a32-9fe1-d817a8fb5094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (8982,)\n",
      "train label shape (8982,)\n",
      "test data shape (2246,)\n",
      "test label shape (2246,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "# load data\n",
    "(tr_data,tr_label),(te_data,te_label) = reuters.load_data(num_words=10000)\n",
    "print(\"train data shape\",tr_data.shape)\n",
    "print(\"train label shape\",tr_label.shape)\n",
    "print(\"test data shape\",te_data.shape)\n",
    "print(\"test label shape\",te_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb0c1af-40fe-4130-88f3-7f529c1ff146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1 ---  [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "train Label 1 ---  3\n",
      "you index ---  1025\n"
     ]
    }
   ],
   "source": [
    "print(\"train 1 --- \",tr_data[0])\n",
    "print(\"train Label 1 --- \",tr_label[0])\n",
    "index_of_word = reuters.get_word_index()\n",
    "you_index = index_of_word['you']\n",
    "print(\"you index --- \",you_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c54ad9-76d5-40a8-955a-ee58eeba1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data new shape (8982, 200)\n",
      "test data new shape (2246, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "# 固定每篇報導的長度為 200 字\n",
    "word_len = 200\n",
    "tr_data_new = sequence.pad_sequences(tr_data,maxlen=word_len)\n",
    "te_data_new = sequence.pad_sequences(te_data,maxlen=word_len)\n",
    "print(\"train data new shape\",tr_data_new.shape)\n",
    "print(\"test data new shape\",te_data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f298ab06-438e-488e-bbb0-43cf146d613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本身已知有46種主題\n",
    "# 將 label 進行 one hot encode\n",
    "total_class = 46\n",
    "tr_encode = tf.one_hot(tr_label,depth=total_class)\n",
    "te_encode = tf.one_hot(te_label,depth=total_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef76cf95-2e5d-4a85-868d-17249c30483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(10000,\n",
    "                          output_dim=200,\n",
    "                          input_length=word_len))\n",
    "model.add(layers.LSTM(128,dropout=0.5,return_sequences=True))\n",
    "model.add(layers.LSTM(128,dropout=0.5))\n",
    "model.add(layers.Dense(total_class,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80ed7b1-e181-4b36-b1fd-f2b13291e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "225/225 - 36s - 159ms/step - acc: 0.4720 - loss: 2.0635 - val_acc: 0.4363 - val_loss: 2.1181\n",
      "Epoch 2/25\n",
      "225/225 - 38s - 167ms/step - acc: 0.5503 - loss: 1.7486 - val_acc: 0.5771 - val_loss: 1.6808\n",
      "Epoch 3/25\n",
      "225/225 - 37s - 166ms/step - acc: 0.5891 - loss: 1.6158 - val_acc: 0.5838 - val_loss: 1.6759\n",
      "Epoch 4/25\n",
      "225/225 - 37s - 166ms/step - acc: 0.6206 - loss: 1.4981 - val_acc: 0.6016 - val_loss: 1.5385\n",
      "Epoch 5/25\n",
      "225/225 - 38s - 170ms/step - acc: 0.6349 - loss: 1.4233 - val_acc: 0.6038 - val_loss: 1.5684\n",
      "Epoch 6/25\n",
      "225/225 - 39s - 174ms/step - acc: 0.6548 - loss: 1.3294 - val_acc: 0.6372 - val_loss: 1.4198\n",
      "Epoch 7/25\n",
      "225/225 - 38s - 169ms/step - acc: 0.6692 - loss: 1.2646 - val_acc: 0.6366 - val_loss: 1.3867\n",
      "Epoch 8/25\n",
      "225/225 - 38s - 167ms/step - acc: 0.6841 - loss: 1.2012 - val_acc: 0.6672 - val_loss: 1.3474\n",
      "Epoch 9/25\n",
      "225/225 - 38s - 168ms/step - acc: 0.7040 - loss: 1.1277 - val_acc: 0.6644 - val_loss: 1.3600\n",
      "Epoch 10/25\n",
      "225/225 - 41s - 182ms/step - acc: 0.7194 - loss: 1.0717 - val_acc: 0.6845 - val_loss: 1.3064\n",
      "Epoch 11/25\n",
      "225/225 - 38s - 168ms/step - acc: 0.7278 - loss: 1.0428 - val_acc: 0.6667 - val_loss: 1.3370\n",
      "Epoch 12/25\n",
      "225/225 - 39s - 174ms/step - acc: 0.7375 - loss: 1.0000 - val_acc: 0.6917 - val_loss: 1.2970\n",
      "Epoch 13/25\n",
      "225/225 - 38s - 168ms/step - acc: 0.7559 - loss: 0.9439 - val_acc: 0.6945 - val_loss: 1.2608\n",
      "Epoch 14/25\n",
      "225/225 - 39s - 172ms/step - acc: 0.7628 - loss: 0.9162 - val_acc: 0.6850 - val_loss: 1.2934\n",
      "Epoch 15/25\n",
      "225/225 - 38s - 167ms/step - acc: 0.7678 - loss: 0.8883 - val_acc: 0.6895 - val_loss: 1.2484\n",
      "Epoch 16/25\n",
      "225/225 - 39s - 173ms/step - acc: 0.7775 - loss: 0.8497 - val_acc: 0.6928 - val_loss: 1.3116\n",
      "Epoch 17/25\n",
      "225/225 - 38s - 170ms/step - acc: 0.7872 - loss: 0.8121 - val_acc: 0.6962 - val_loss: 1.2494\n",
      "Epoch 18/25\n",
      "225/225 - 39s - 173ms/step - acc: 0.7981 - loss: 0.7857 - val_acc: 0.7034 - val_loss: 1.2638\n",
      "Epoch 19/25\n",
      "225/225 - 39s - 172ms/step - acc: 0.8064 - loss: 0.7559 - val_acc: 0.6884 - val_loss: 1.3090\n",
      "Epoch 20/25\n",
      "225/225 - 39s - 171ms/step - acc: 0.8117 - loss: 0.7291 - val_acc: 0.7134 - val_loss: 1.2704\n",
      "Epoch 21/25\n",
      "225/225 - 41s - 181ms/step - acc: 0.8168 - loss: 0.7115 - val_acc: 0.7151 - val_loss: 1.2355\n",
      "Epoch 22/25\n",
      "225/225 - 38s - 168ms/step - acc: 0.8253 - loss: 0.6858 - val_acc: 0.7129 - val_loss: 1.2498\n",
      "Epoch 23/25\n",
      "225/225 - 38s - 170ms/step - acc: 0.8299 - loss: 0.6525 - val_acc: 0.7179 - val_loss: 1.2756\n",
      "Epoch 24/25\n",
      "225/225 - 38s - 171ms/step - acc: 0.8348 - loss: 0.6419 - val_acc: 0.7145 - val_loss: 1.3226\n",
      "Epoch 25/25\n",
      "225/225 - 38s - 169ms/step - acc: 0.8408 - loss: 0.6203 - val_acc: 0.7229 - val_loss: 1.2642\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - acc: 0.7030 - loss: 1.3415\n",
      "test acc: 0.703027606010437\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "epoch = 25\n",
    "model.compile(\n",
    "    optimizer= 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "model.fit(tr_data_new,tr_encode,\n",
    "         epochs=epoch,\n",
    "         batch_size=batch,\n",
    "         verbose=2,\n",
    "         validation_split=0.2)\n",
    "loss,acc = model.evaluate(te_data_new,te_encode)\n",
    "print('test acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34dcc9b7-e787-4e93-8a49-db62dfe1335a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  510,   17,   12],\n",
       "       [   4,   96, 1043, ...,  760,   17,   12],\n",
       "       [   7, 2775,   33, ...,    8,   17,   12],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   11,   17,   12],\n",
       "       [   0,    0,    0, ...,    8,   17,   12],\n",
       "       [   4,  377,  101, ..., 1523,   17,   12]],\n",
       "      shape=(2246, 200), dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12946302-fbe1-4629-98a6-2f0590d6b8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
